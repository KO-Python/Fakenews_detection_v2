

import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import torch
import pandas as pd
import os
from datetime import datetime
import dropbox

# âœ… ë“œë¡­ë°•ìŠ¤ Access Token (ì„ ìƒë‹˜ì´ ìƒˆë¡œ ë°œê¸‰ í›„ ì—¬ê¸°ì— ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤)
DROPBOX_ACCESS_TOKEN = 'sl.u.AF14tlmf5wnusvJnLa7kmT8mhNd5G4ekeFYkve5LYOrR5wHuX256d4MG41tED1a7kTvg097bKBYtWErJrJSK321o83r9raa_ich1aunfPRlS1KWy8k1fbqTTa6AJWmxi3Q2mrcInJMCRuT2TP1ksvQUMzOy2GX_pRhiYnv6FLc_XYl_eUM8jAp-bmfbPj5DsqypKPAcqU8z7zEvg84KWtkyq5wCUbMSdPsgh7qQGEdPxLTMrZby4yaAiS-T6LLPiu4MZAVfhNhoPOqJxzlp1cJOFuPkwiGfOP16M9YzDwYCEvnaxIvBagGDepJJAKvAsvcVQfmtuNKFaxa-XIEr6Cw3QnOIUbQeh7pwlRX_8Qa4VDhJErXz9tQlM_ZIlxRBcqtUXYfwTDSFHg4HgwdyY0qejUwT5T31s-Q3iEDZOZUAU5KymLA6O21kcQHeUNOnFyaWtGhwhOWMT5LZOe3ITJn7WYIZg1VESl4XedEZa_Vl_K2kQilSBSl-YstxuYTez9uiQsZVBMHr6d9-h4ojrSl2cewPG4Ty579C0Yli3ry56wu0nyt8p6FTtyFZP1j7brtS_D70hT3FPseMcuIwuVub8jQaqPdIAVMbzvv1DstvdXV6542hdYrXPSWJmo1GmSrVk6YWmpQDkXqz--LQfAQ8ruAN1_uZCAx2p6ZgP4I3HccCzqs47WqrHjnCYBJ4fFZR4RB-JRDdshkCp1fwS8ZM3Sb-7o3fmla2uyjHn5JUOnU5PqrjaIn0mc1w8QpjS0rspFIXhzCOmHkpD7L4Sn3rQFrDC5bAXWCOOhro3aJd2uKAdCk6j3rDV1eEu6KdMdWxrPBNvzTM5CFcpeBEntsLuIo29XYkO7clX6P4fckitqvw6HZ4Lu_DgSskVOxKAwm2L4Htf_5281k2lrpOTCqj_QyXyDGbPXt36Qy1NM6fWj6YwRekr4fhUcx2x2ZV5q7OBPAukjxbJx3ROV9-BlzOlAH8z9PWpM3AkRRrcKjzIOmyZlpmPahNI73SIpM1NciG96tccWz3GO14bLDLcMmMFmq06DVt5CNnp8fJIkoiqnC_jS8VIu1JI6GIjIfnUh3o8hjcDPT1GaGjQjyTBN_91AI9ANEIAcuGc_3pm-HbZvk87A0yU9lYHS35-E8jtCW1q-6y_ufo4FnNgVKvkuR4aW3rUtqbXnl0MLKbXo9l2NUzYVBGo51GGKCRGnjBI2En1H6nbiQoo2AgKK34xd7MEKh7j-XrfZJMWgz7y-ds7Wsl7D70A68Igow1Yg6mhvhQ'

# âœ… ë“œë¡­ë°•ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)

# âœ… ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì ìš©)
@st.cache_resource
def load_model():
    model = BertForSequenceClassification.from_pretrained("kbs0035/my_fakenews_model")
    tokenizer = BertTokenizer.from_pretrained("kbs0035/my_fakenews_model")
    model.eval()
    return model, tokenizer

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model, tokenizer = load_model()

# âœ… Streamlit UI êµ¬ì„±
st.title("í—ˆìœ„ì •ë³´ íƒì§€ AI ì„œë¹„ìŠ¤")

# âœ… ì°¸ì—¬ì ê¸°ë³¸ ì •ë³´ ì…ë ¥
st.subheader("ì°¸ì—¬ì ê¸°ë³¸ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”")

user_id = st.text_input("ì°¸ì—¬ì½”ë“œ (ë³¸ì¸ ì „í™”ë²ˆí˜¸ ë 4ìë¦¬ ë˜ëŠ” ì„ì˜ 4ìë¦¬)")

gender = st.selectbox("ì„±ë³„", ["ì„ íƒí•˜ì„¸ìš”", "ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€/ì‘ë‹µì•ˆí•¨"])

age = st.number_input("ë‚˜ì´ (ìˆ«ì ì…ë ¥)", min_value=10, max_value=100, step=1)

region = st.selectbox(
    "ê±°ì£¼ì§€ì—­",
    ["ì„ íƒí•˜ì„¸ìš”", "ì„œìš¸", "ìˆ˜ë„ê¶Œ(ê²½ê¸°/ì¸ì²œ)", "ì¶©ì²­ê¶Œ", "ì˜ë‚¨ê¶Œ", "í˜¸ë‚¨ê¶Œ", "ê°•ì›/ì œì£¼", "ê¸°íƒ€"]
)

political_ideology = st.slider(
    "ì •ì¹˜ ì´ë… ì„±í–¥ (1 = ë§¤ìš° ì§„ë³´ì , 10 = ë§¤ìš° ë³´ìˆ˜ì ) â†’ ì´ë™í•´ì„œ ì„ íƒí•´ì£¼ì„¸ìš”", 1, 10, 5
)

party_support = st.selectbox(
    "í˜„ì¬ ì§€ì§€í•˜ëŠ” ì •ë‹¹",
    ["ì„ íƒí•˜ì„¸ìš”", "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜", "ì •ì˜ë‹¹", "ê¸°íƒ€ ì •ë‹¹", "ì§€ì§€ ì •ë‹¹ ì—†ìŒ"]
)

# âœ… ê²€ìƒ‰ íšŸìˆ˜ ì¹´ìš´íŠ¸ (1~5ê°œ ì œí•œ)
if 'search_count' not in st.session_state:
    st.session_state['search_count'] = 0

st.write(f"í˜„ì¬ ê²€ìƒ‰ íšŸìˆ˜: {st.session_state['search_count']} / 5 (ìµœì†Œ 1ê°œ ~ ìµœëŒ€ 5ê°œê¹Œì§€ ê²€ìƒ‰ ê°€ëŠ¥)")

# âœ… ê¸°ì‚¬ ì…ë ¥
st.subheader("ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
user_input = st.text_area("ê¸°ì‚¬ ì…ë ¥", height=150)

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("í—ˆìœ„ì •ë³´ íƒìƒ‰í•˜ê¸°"):
    # ì…ë ¥ í™•ì¸
    if user_id.strip() == "" or gender == "ì„ íƒí•˜ì„¸ìš”" or region == "ì„ íƒí•˜ì„¸ìš”" or party_support == "ì„ íƒí•˜ì„¸ìš”" or user_input.strip() == "":
        st.warning("âš ï¸ ì°¸ì—¬ì½”ë“œ, ì„±ë³„, ê±°ì£¼ì§€ì—­, ì§€ì§€ì •ë‹¹, ê¸°ì‚¬ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif st.session_state['search_count'] >= 5:
        st.warning("âš ï¸ ìµœëŒ€ 5ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(user_input, return_tensors="pt", max_length=128, truncation=True, padding="max_length")

        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            prediction = torch.argmax(logits, dim=1).item()
            probabilities = torch.softmax(logits, dim=1)
            confidence = probabilities[0][prediction].item() * 100

        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        if prediction == 1:
            st.error(f"âŒ í—ˆìœ„ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "í—ˆìœ„"
        else:
            st.success(f"âœ… ì§„ì‹¤ëœ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "ì§„ì‹¤"

        # ê²€ìƒ‰ ë¡œê·¸ ì €ì¥
        log_entry = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_id': user_id,
            'gender': gender,
            'age': age,
            'region': region,
            'political_ideology': political_ideology,
            'party_support': party_support,
            'search_count': st.session_state['search_count'] + 1,
            'user_input': user_input,
            'result': result_text,
            'confidence': round(confidence, 2)
        }

        log_file = 'search_log.csv'

        if os.path.exists(log_file):
            df_log = pd.read_csv(log_file)
            df_log = pd.concat([df_log, pd.DataFrame([log_entry])], ignore_index=True)
        else:
            df_log = pd.DataFrame([log_entry])

        df_log.to_csv(log_file, index=False)
        st.info("âœ… ê²€ìƒ‰ ë‚´ìš©ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # âœ… ë“œë¡­ë°•ìŠ¤ì— ì—…ë¡œë“œ
        try:
            with open("search_log.csv", "rb") as f:
                dbx.files_upload(f.read(), "/FakeNews/search_log.csv", mode=dropbox.files.WriteMode.overwrite)
            st.success("âœ… ë“œë¡­ë°•ìŠ¤ ì €ì¥ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ ë“œë¡­ë°•ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

        # âœ… ê²€ìƒ‰ ì¹´ìš´íŠ¸ ì¦ê°€
        st.session_state['search_count'] += 1

# âœ… ê²€ìƒ‰ ì™„ë£Œ ì•ˆë‚´
if st.session_state['search_count'] == 5:
    st.success("ğŸ‰ 5ê°œ ì…ë ¥ ì™„ë£Œ! ì„¤ë¬¸ì„ ì¢…ë£Œí•˜ì…”ë„ ë©ë‹ˆë‹¤.")



