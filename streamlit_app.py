import streamlit as st
import torch
from transformers import BertTokenizer
from model import MultiOutputBERT

# ëª¨ë¸ ë¡œë“œ
@st.cache_resource(show_spinner=False)
def load_model():
    model = MultiOutputBERT(
        pretrained_model_name='klue/bert-base',
        num_category_labels=8,
        num_target_labels=12
    )
    model.load_state_dict(torch.load("saved_model/hate_speech_model.pt", map_location='cpu'))
    model.eval()
    return model

# í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = BertTokenizer.from_pretrained('klue/bert-base')
model = load_model()

# ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
category_list = ['ê³µê²©', 'ëª¨ìš•', 'ë°°ì œ', 'ë¹„ë°©', 'ë¹„í•˜', 'ì¡°ë¡±', 'ì¦ì˜¤', 'í„í•˜']
target_list = ['ê³µë¬´ì›', 'ê¸°ë…êµ', 'ë‚¨ì„±', 'ì„±ì†Œìˆ˜ì', 'ì•„ì‹œì•„ì¸', 'ì—¬ì„±',
               'ì´ë¯¼ì', 'ì´ìŠ¬ëŒêµ', 'ì¥ì• ì¸', 'ì •ì¹˜ì¸', 'ì²­ì†Œë…„', 'í‘ì¸']

# UI êµ¬ì„±
st.title("ğŸ›¡ï¸ í˜ì˜¤ í‘œí˜„ íƒì§€ê¸°")

text = st.text_area(
    "ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:",
    placeholder="ì˜ˆ: ì •ì¹˜ì¸ì€ ì¡´ì¬ ìì²´ê°€ ë¶ˆì¾Œí•˜ë‹¤."
)

st.caption("ğŸ“ ì˜ˆ: ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°ë‚˜ ì†Œì…œë¯¸ë””ì–´ì—ì„œ ì ‘í•œ í˜ì˜¤ í‘œí˜„ì´ ì˜ì‹¬ë˜ëŠ” ë¬¸ì¥ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")

if st.button("ë¶„ì„í•˜ê¸°"):
    if not text.strip():
        st.warning("âš ï¸ ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
        if "token_type_ids" not in inputs:
            inputs["token_type_ids"] = torch.zeros_like(inputs["input_ids"])
        with torch.no_grad():
            cat_logits, tar_logits = model(**inputs)
            cat_pred = torch.argmax(cat_logits, dim=1).item()
            tar_pred = torch.argmax(tar_logits, dim=1).item()

        st.success(f"ğŸ“‚ Category: **{category_list[cat_pred]}**")
        st.success(f"ğŸ¯ Target: **{target_list[tar_pred]}**")