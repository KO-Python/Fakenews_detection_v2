

import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import torch
import pandas as pd
import os
from datetime import datetime
import dropbox

# âœ… ë“œë¡­ë°•ìŠ¤ Access Token (ì„ ìƒë‹˜ì´ ìƒˆë¡œ ë°œê¸‰ í›„ ì—¬ê¸°ì— ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤)
DROPBOX_ACCESS_TOKEN = 'sl.u.AF2IfaMHeFvyeZwxy8QB5prGjCUMF2HX6ghef98nNZMBdhZZn0ZePztY2iguCN6Qvg4IX2ib6hlSJcI5T9UjwcYVe3ATvlJmaN451pBTLgvsrJWX785UhBjey3M13w2qiVdpGAB2fgl8bKrmikP1vgQSvf73toCzLnwy_T8Awr7xAGSk952oqCuIREk5KW_2_4vVmK3eREkVfEwy8y0_zxuo1g88dTG1ibc2SSFJszMv4iQCh-Q-AE7oYrc5xeHIEg4NGbDLK5k0kMr82oAVFJ3hmty8ApBHyn7ozRAHYny7-4g1oebcyTrpHe1P3iGwOV-MRsAFdtOJKQ3_gcaePNOnWWMCGMf8En4HInGHpxWY43K4rRbHyPxkTrAX9r6Pva8ItsKkeXWsLytCNlOxqcdSQxEpZpVw9R8_31cNxZX5wQVUGFfWq-sfKne5Sf3TB55arNNMJZFEuOza9Dxmm8q0bQD-PXUIzKrOo8764w9UxNc3zZhE1G8UIFDqiWwUrwf7i-dlysBEj__T3AVprH5q21ZOddVRnTE1S519D21slhQq00e6flLWOsMDtaWBY1pRMFRDKA97f1hSqoL_NYPTCfdT9oykNM7NHdI5Ym5atW1iGGU31QGrZDZKk0LaIeIZF46NXW5H5PG9XlUrr5ViwCgimguL4wAgV3Z_XA1kUg3EcRA1XffiWvSlLIDQX_SbspcfOXI1_cUtHxeXebiZ1aRPbvaw0x9YyECCHf_7cSazQIrGJQR9MrUqkaNvNdV13AU3-uxAhXe5RSVeE70zql4-qtLh0SNafa9-aXpbt3FfykyOlkOjpL6yveYg1Kfy9Xddv0wHL1fhL3t34U1pDJBM7DdVUDJvXzNmOaYz1L5OVZFgidCQ84a1w4xrDbJB-KPUG43MY_wDT0JQUF1VpAJ-0kHg6n4CP-s5aDaswZATvj7yK_OPiktYSOP6on2r3s6PWsqlwyd84wpCEnfxnWlwVI0ZdMcd1o290oQMIz710bwANgqtBcpxwQFAcjL1dF19q_QcKUjLIWoVj2unnNCHzyrDij4cXvwxMliiThZavB1v53ZNyAyJpxRnW1sTy-r5_xYJq0OCw4fbP5aWDP2nWVZTmQ2gL-jYZXM6EKfGuuoWGApH2eHYQ_rnDOxUlaLFqa75BHFLIze1MF-WgIQ6UjG2BhvSRfwPwr8ZDPNX-GaDeQUfY6DOkV3MnG-VYWARxHDqXeE5iTxNsPKLiWZxE0XVFsfP4s6XVdgV72kohMJ9KAZlGJovERNW3fc'

# âœ… ë“œë¡­ë°•ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)

# âœ… ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì ìš©)
@st.cache_resource
def load_model():
    model = BertForSequenceClassification.from_pretrained("kbs0035/my_fakenews_model")
    tokenizer = BertTokenizer.from_pretrained("kbs0035/my_fakenews_model")
    model.eval()
    return model, tokenizer

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model, tokenizer = load_model()

# âœ… Streamlit UI êµ¬ì„±
st.title("í—ˆìœ„ì •ë³´ íƒì§€ AI ì„œë¹„ìŠ¤")

# âœ… ì°¸ì—¬ì ê¸°ë³¸ ì •ë³´ ì…ë ¥
st.subheader("ì°¸ì—¬ì ê¸°ë³¸ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”")

user_id = st.text_input("ì°¸ì—¬ì½”ë“œ (ë³¸ì¸ ì „í™”ë²ˆí˜¸ ë 4ìë¦¬ ë˜ëŠ” ì„ì˜ 4ìë¦¬)")

gender = st.selectbox("ì„±ë³„", ["ì„ íƒí•˜ì„¸ìš”", "ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€/ì‘ë‹µì•ˆí•¨"])

age = st.number_input("ë‚˜ì´ (ìˆ«ì ì…ë ¥)", min_value=10, max_value=100, step=1)

region = st.selectbox(
    "ê±°ì£¼ì§€ì—­",
    ["ì„ íƒí•˜ì„¸ìš”", "ì„œìš¸", "ìˆ˜ë„ê¶Œ(ê²½ê¸°/ì¸ì²œ)", "ì¶©ì²­ê¶Œ", "ì˜ë‚¨ê¶Œ", "í˜¸ë‚¨ê¶Œ", "ê°•ì›/ì œì£¼", "ê¸°íƒ€"]
)

political_ideology = st.slider(
    "ì •ì¹˜ ì´ë… ì„±í–¥ (1 = ë§¤ìš° ì§„ë³´ì , 10 = ë§¤ìš° ë³´ìˆ˜ì ) â†’ ì´ë™í•´ì„œ ì„ íƒí•´ì£¼ì„¸ìš”", 1, 10, 5
)

party_support = st.selectbox(
    "í˜„ì¬ ì§€ì§€í•˜ëŠ” ì •ë‹¹",
    ["ì„ íƒí•˜ì„¸ìš”", "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜", "ì •ì˜ë‹¹", "ê¸°íƒ€ ì •ë‹¹", "ì§€ì§€ ì •ë‹¹ ì—†ìŒ"]
)

# âœ… ê²€ìƒ‰ íšŸìˆ˜ ì¹´ìš´íŠ¸ (1~5ê°œ ì œí•œ)
if 'search_count' not in st.session_state:
    st.session_state['search_count'] = 0

st.write(f"í˜„ì¬ ê²€ìƒ‰ íšŸìˆ˜: {st.session_state['search_count']} / 5 (ìµœì†Œ 1ê°œ ~ ìµœëŒ€ 5ê°œê¹Œì§€ ê²€ìƒ‰ ê°€ëŠ¥)")

# âœ… ê¸°ì‚¬ ì…ë ¥
st.subheader("ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
user_input = st.text_area("ê¸°ì‚¬ ì…ë ¥", height=150)

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("í—ˆìœ„ì •ë³´ íƒìƒ‰í•˜ê¸°"):
    # ì…ë ¥ í™•ì¸
    if user_id.strip() == "" or gender == "ì„ íƒí•˜ì„¸ìš”" or region == "ì„ íƒí•˜ì„¸ìš”" or party_support == "ì„ íƒí•˜ì„¸ìš”" or user_input.strip() == "":
        st.warning("âš ï¸ ì°¸ì—¬ì½”ë“œ, ì„±ë³„, ê±°ì£¼ì§€ì—­, ì§€ì§€ì •ë‹¹, ê¸°ì‚¬ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif st.session_state['search_count'] >= 5:
        st.warning("âš ï¸ ìµœëŒ€ 5ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(user_input, return_tensors="pt", max_length=128, truncation=True, padding="max_length")

        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            prediction = torch.argmax(logits, dim=1).item()
            probabilities = torch.softmax(logits, dim=1)
            confidence = probabilities[0][prediction].item() * 100

        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        if prediction == 1:
            st.error(f"âŒ í—ˆìœ„ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "í—ˆìœ„"
        else:
            st.success(f"âœ… ì§„ì‹¤ëœ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "ì§„ì‹¤"

        # ê²€ìƒ‰ ë¡œê·¸ ì €ì¥
        log_entry = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_id': user_id,
            'gender': gender,
            'age': age,
            'region': region,
            'political_ideology': political_ideology,
            'party_support': party_support,
            'search_count': st.session_state['search_count'] + 1,
            'user_input': user_input,
            'result': result_text,
            'confidence': round(confidence, 2)
        }

        log_file = 'search_log.csv'

        if os.path.exists(log_file):
            df_log = pd.read_csv(log_file)
            df_log = pd.concat([df_log, pd.DataFrame([log_entry])], ignore_index=True)
        else:
            df_log = pd.DataFrame([log_entry])

        df_log.to_csv(log_file, index=False)
        st.info("âœ… ê²€ìƒ‰ ë‚´ìš©ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # âœ… ë“œë¡­ë°•ìŠ¤ì— ì—…ë¡œë“œ
        try:
            with open("search_log.csv", "rb") as f:
                dbx.files_upload(f.read(), "/FakeNews/search_log.csv", mode=dropbox.files.WriteMode.overwrite)
            st.success("âœ… ë“œë¡­ë°•ìŠ¤ ì €ì¥ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ ë“œë¡­ë°•ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

        # âœ… ê²€ìƒ‰ ì¹´ìš´íŠ¸ ì¦ê°€
        st.session_state['search_count'] += 1

# âœ… ê²€ìƒ‰ ì™„ë£Œ ì•ˆë‚´
if st.session_state['search_count'] == 5:
    st.success("ğŸ‰ 5ê°œ ì…ë ¥ ì™„ë£Œ! ì„¤ë¬¸ì„ ì¢…ë£Œí•˜ì…”ë„ ë©ë‹ˆë‹¤.")



