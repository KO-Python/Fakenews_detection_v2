
import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import torch
import pandas as pd
import os
from datetime import datetime

# ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì ìš©)
@st.cache_resource
def load_model():
    model = BertForSequenceClassification.from_pretrained("kbs0035/my_fakenews_model")
    tokenizer = BertTokenizer.from_pretrained("kbs0035/my_fakenews_model")
    model.eval()
    return model, tokenizer

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model, tokenizer = load_model()

# Streamlit UI êµ¬ì„±
st.title("í—ˆìœ„ì •ë³´ íƒì§€ AI ì„œë¹„ìŠ¤")

# ğŸ‘‰ ìƒˆ ì ‘ì† ì‚¬ìš©ìì—ê²Œ session_state ì´ˆê¸°í™” (ìë™)
if 'first_run' not in st.session_state:
    st.session_state['search_count'] = 0
    st.session_state['first_run'] = False

# ì°¸ì—¬ì ê¸°ë³¸ ì •ë³´ ì…ë ¥
st.subheader("1ï¸âƒ£ ì°¸ì—¬ì ê¸°ë³¸ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”")

user_id = st.text_input("ì°¸ì—¬ì½”ë“œ (ë³¸ì¸ ì „í™”ë²ˆí˜¸ ë 4ìë¦¬ ë˜ëŠ” ì„ì˜ 4ìë¦¬)")
gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€/ì‘ë‹µì•ˆí•¨"])
age = st.number_input("ë‚˜ì´ (ìˆ«ì ì…ë ¥)", min_value=10, max_value=100, step=1)
region = st.selectbox("ê±°ì£¼ì§€ì—­", ["ì„œìš¸", "ìˆ˜ë„ê¶Œ(ê²½ê¸°/ì¸ì²œ)", "ì¶©ì²­ê¶Œ", "ì˜ë‚¨ê¶Œ", "í˜¸ë‚¨ê¶Œ", "ê°•ì›/ì œì£¼", "ê¸°íƒ€"])
political_ideology = st.slider("ì •ì¹˜ ì´ë… ì„±í–¥ (1 = ë§¤ìš° ì§„ë³´ì , 7 = ë§¤ìš° ë³´ìˆ˜ì )", 1, 7, 4)
party_support = st.selectbox("í˜„ì¬ ì§€ì§€í•˜ëŠ” ì •ë‹¹", ["ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜", "ì •ì˜ë‹¹", "ê¸°íƒ€ ì •ë‹¹", "ì§€ì§€ ì •ë‹¹ ì—†ìŒ"])

# ê²€ìƒ‰ íšŸìˆ˜ ì¹´ìš´íŠ¸ (1~5ê°œ ì œí•œ)
st.write(f"í˜„ì¬ ê²€ìƒ‰ íšŸìˆ˜: {st.session_state['search_count']} / 5 (ìµœì†Œ 1ê°œ ~ ìµœëŒ€ 5ê°œê¹Œì§€ ê²€ìƒ‰ ê°€ëŠ¥)")

# ê¸°ì‚¬ ì…ë ¥
st.subheader("2ï¸âƒ£ ê¸°ì‚¬ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
user_input = st.text_area("ê¸°ì‚¬ ì…ë ¥", height=150)

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("í—ˆìœ„ì •ë³´ íƒìƒ‰í•˜ê¸°"):
    # ì…ë ¥ í™•ì¸
    if user_id.strip() == "" or user_input.strip() == "":
        st.warning("ì°¸ì—¬ì½”ë“œì™€ ê¸°ì‚¬ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    elif st.session_state['search_count'] >= 5:
        st.warning("ìµœëŒ€ 5ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(user_input, return_tensors="pt", max_length=128, truncation=True, padding="max_length")

        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            prediction = torch.argmax(logits, dim=1).item()
            probabilities = torch.softmax(logits, dim=1)
            confidence = probabilities[0][prediction].item() * 100

        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        if prediction == 1:
            st.error(f"âŒ í—ˆìœ„ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "í—ˆìœ„"
        else:
            st.success(f"âœ… ì§„ì‹¤ëœ ì •ë³´ ê°€ëŠ¥ì„± ë†’ìŒ. (ì‹ ë¢°ë„: {confidence:.2f}%)")
            result_text = "ì§„ì‹¤"

        # ê²€ìƒ‰ ë¡œê·¸ ì €ì¥
        log_entry = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_id': user_id,
            'gender': gender,
            'age': age,
            'region': region,
            'political_ideology': political_ideology,
            'party_support': party_support,
            'search_count': st.session_state['search_count'] + 1,
            'user_input': user_input,
            'result': result_text,
            'confidence': round(confidence, 2)
        }

        log_file = 'search_log.csv'

        if os.path.exists(log_file):
            df_log = pd.read_csv(log_file)
            df_log = pd.concat([df_log, pd.DataFrame([log_entry])], ignore_index=True)
        else:
            df_log = pd.DataFrame([log_entry])

        df_log.to_csv(log_file, index=False)
        st.info("ê²€ìƒ‰ ë‚´ìš©ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê²€ìƒ‰ ì¹´ìš´íŠ¸ ì¦ê°€
        st.session_state['search_count'] += 1

# ê²€ìƒ‰ ì™„ë£Œ ì•ˆë‚´
if st.session_state['search_count'] == 5:
    st.success("5ê°œ ì…ë ¥ ì™„ë£Œ! ì„¤ë¬¸ì„ ì¢…ë£Œí•˜ì…”ë„ ë©ë‹ˆë‹¤.")

